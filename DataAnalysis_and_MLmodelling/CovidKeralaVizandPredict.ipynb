{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid-19 Number of Deaths prediction in the state of Kerala , India. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Initializaing Pyspark for jupyter NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/ashwinv/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "import plotly.offline as py\n",
    "import plotly_express as px\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builidng spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"CovidIndia\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.read.csv(\"/Users/ashwinv/Documents/SEM4/BigData/Project/Datasets/covidindia.csv\", header=True, mode=\"DROPMALFORMED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidData = lines.select(\"State/UnionTerritory\",\"Confirmed\",\"Cured\",\"Deaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+------+\n",
      "|State/UnionTerritory|Confirmed|Cured|Deaths|\n",
      "+--------------------+---------+-----+------+\n",
      "|              Kerala|        1|    0|     0|\n",
      "|              Kerala|        1|    0|     0|\n",
      "|              Kerala|        2|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|           Telengana|        1|    0|     0|\n",
      "|              Kerala|        3|    0|     0|\n",
      "|               Delhi|        1|    0|     0|\n",
      "|           Telengana|        1|    0|     0|\n",
      "|           Rajasthan|        1|    0|     0|\n",
      "|              Kerala|        3|    3|     0|\n",
      "|               Delhi|        1|    0|     0|\n",
      "|       Uttar Pradesh|        6|    0|     0|\n",
      "|              Kerala|        3|    3|     0|\n",
      "|             Haryana|        2|    0|     0|\n",
      "|               Delhi|        1|    0|     0|\n",
      "|           Telengana|        1|    0|     0|\n",
      "|           Rajasthan|       15|    0|     0|\n",
      "|               Delhi|        2|    0|     0|\n",
      "|             Haryana|        2|    0|     0|\n",
      "|              Kerala|        3|    3|     0|\n",
      "|           Rajasthan|       15|    0|     0|\n",
      "|           Telengana|        1|    0|     0|\n",
      "+--------------------+---------+-----+------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd1 = covidData.fillna(\"unknown\")\n",
    "pd1.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State/UnionTerritory: string (nullable = true)\n",
      " |-- Confirmed: string (nullable = true)\n",
      " |-- Cured: string (nullable = true)\n",
      " |-- Deaths: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covidData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(covidData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>State/UnionTerritory</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Cured</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>9291</td>\n",
       "      <td>9291</td>\n",
       "      <td>9291</td>\n",
       "      <td>9291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>91839.78355397697</td>\n",
       "      <td>78632.66020880421</td>\n",
       "      <td>1487.620385319126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>None</td>\n",
       "      <td>216601.36826584276</td>\n",
       "      <td>193110.2283333888</td>\n",
       "      <td>4713.81369001881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>99930</td>\n",
       "      <td>99988</td>\n",
       "      <td>9984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary         State/UnionTerritory           Confirmed              Cured  \\\n",
       "0   count                         9291                9291               9291   \n",
       "1    mean                         None   91839.78355397697  78632.66020880421   \n",
       "2  stddev                         None  216601.36826584276  193110.2283333888   \n",
       "3     min  Andaman and Nicobar Islands                   0                  0   \n",
       "4     max                  West Bengal               99930              99988   \n",
       "\n",
       "              Deaths  \n",
       "0               9291  \n",
       "1  1487.620385319126  \n",
       "2   4713.81369001881  \n",
       "3                  0  \n",
       "4               9984  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covidData.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CovidindiaVisualization.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines2 = spark.read.csv(\"/Users/ashwinv/Documents/SEM4/BigData/Project/Datasets/COVID-19CoronaVirusIndiaDataset/complete.csv\", header=True, mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidData2 = lines2.select(\"Date\",\"Name of State / UT\",\"Total Confirmed cases\",\"Death\",\"Cured/Discharged/Migrated\")\n",
    "cd2 = covidData2.fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DateType\n",
    "cd2 = cd2.withColumn(\"Date\",cd2['Date'].cast(DateType()))\n",
    "cd2 = cd2.withColumn(\"Death\",cd2['Death'].cast(IntegerType()))\n",
    "cd2 = cd2.withColumn(\"Total Confirmed cases\",cd2['Total Confirmed cases'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Name of State / UT: string (nullable = false)\n",
      " |-- Total Confirmed cases: integer (nullable = true)\n",
      " |-- Death: integer (nullable = true)\n",
      " |-- Cured/Discharged/Migrated: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------------------+-----+-------------------------+\n",
      "|      Date|Name of State / UT|Total Confirmed cases|Death|Cured/Discharged/Migrated|\n",
      "+----------+------------------+---------------------+-----+-------------------------+\n",
      "|2020-01-30|            Kerala|                    1|    0|                      0.0|\n",
      "|2020-01-31|            Kerala|                    1|    0|                      0.0|\n",
      "|2020-02-01|            Kerala|                    2|    0|                      0.0|\n",
      "|2020-02-02|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-03|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-04|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-05|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-06|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-07|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-08|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-09|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-10|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-11|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-12|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-13|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-14|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-15|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-16|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-17|            Kerala|                    3|    0|                      0.0|\n",
      "|2020-02-18|            Kerala|                    3|    0|                      0.0|\n",
      "+----------+------------------+---------------------+-----+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------------+\n",
      "|  Name of State / UT|max(Total Confirmed cases)|\n",
      "+--------------------+--------------------------+\n",
      "|            Nagaland|                      2498|\n",
      "|           Karnataka|                    151449|\n",
      "|              Odisha|                     39018|\n",
      "|              Kerala|                     29151|\n",
      "|              Ladakh|                      1592|\n",
      "|Dadra and Nagar H...|                      1366|\n",
      "|          Tamil Nadu|                    273460|\n",
      "|           Telengana|                      4111|\n",
      "|        Chhattisgarh|                     10407|\n",
      "|      Andhra Pradesh|                    186461|\n",
      "|      Madhya Pradesh|                     35734|\n",
      "|              Punjab|                     19856|\n",
      "|             Manipur|                      3093|\n",
      "|                 Goa|                      7423|\n",
      "|             Mizoram|                       537|\n",
      "|    Himachal Pradesh|                      2916|\n",
      "|          Puducherry|                      4433|\n",
      "|             Haryana|                     38548|\n",
      "|   Jammu and Kashmir|                     22955|\n",
      "|           Jharkhand|                     14888|\n",
      "|        Telangana***|                     52466|\n",
      "|   Arunachal Pradesh|                      1855|\n",
      "|             Gujarat|                     66669|\n",
      "|              Sikkim|                       800|\n",
      "|               Delhi|                    140232|\n",
      "|          Chandigarh|                      1270|\n",
      "|           Rajasthan|                     47272|\n",
      "|Andaman and Nicob...|                      1027|\n",
      "|               Assam|                     50445|\n",
      "|Union Territory o...|                         4|\n",
      "|           Meghalaya|                       929|\n",
      "|Union Territory o...|                         1|\n",
      "|         Maharashtra|                    468265|\n",
      "|         West Bengal|                     83800|\n",
      "|           Telangana|                     73050|\n",
      "|               Bihar|                     64770|\n",
      "|Union Territory o...|                        10|\n",
      "|             Tripura|                      5725|\n",
      "|       Uttar Pradesh|                    104388|\n",
      "|         Uttarakhand|                      8254|\n",
      "+--------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd2.groupBy('Name of State / UT').max('Total Confirmed cases').show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd2gp = cd2.groupBy('Name of State / UT').max('Death')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|  Name of State / UT|max(Death)|\n",
      "+--------------------+----------+\n",
      "|            Nagaland|         6|\n",
      "|           Karnataka|      2804|\n",
      "|              Odisha|       225|\n",
      "|              Kerala|        94|\n",
      "|              Ladakh|         7|\n",
      "|Dadra and Nagar H...|         2|\n",
      "|          Tamil Nadu|      4461|\n",
      "|           Telengana|       156|\n",
      "|        Chhattisgarh|        71|\n",
      "|      Andhra Pradesh|      1681|\n",
      "|      Madhya Pradesh|       929|\n",
      "|              Punjab|       491|\n",
      "|             Manipur|         7|\n",
      "|                 Goa|        64|\n",
      "|             Mizoram|         0|\n",
      "|    Himachal Pradesh|        14|\n",
      "|          Puducherry|        65|\n",
      "|             Haryana|       455|\n",
      "|   Jammu and Kashmir|       426|\n",
      "|           Jharkhand|       136|\n",
      "|        Telangana***|       455|\n",
      "|   Arunachal Pradesh|         3|\n",
      "|             Gujarat|      2556|\n",
      "|              Sikkim|         1|\n",
      "|               Delhi|      4044|\n",
      "|          Chandigarh|        20|\n",
      "|           Rajasthan|       745|\n",
      "|Andaman and Nicob...|        14|\n",
      "|               Assam|       121|\n",
      "|Union Territory o...|         0|\n",
      "|           Meghalaya|         5|\n",
      "|Union Territory o...|         0|\n",
      "|         Maharashtra|     16476|\n",
      "|         West Bengal|      1846|\n",
      "|           Telangana|       589|\n",
      "|               Bihar|       355|\n",
      "|Union Territory o...|         0|\n",
      "|             Tripura|        31|\n",
      "|       Uttar Pradesh|      1857|\n",
      "|         Uttarakhand|        98|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd2gp.show(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------+----------+-----+\n",
      "|Name of State / UT|Total Confirmed cases|      Date|Death|\n",
      "+------------------+---------------------+----------+-----+\n",
      "|            Kerala|                    1|2020-01-30|    0|\n",
      "|            Kerala|                    1|2020-01-31|    0|\n",
      "|            Kerala|                    2|2020-02-01|    0|\n",
      "|            Kerala|                    3|2020-02-02|    0|\n",
      "|            Kerala|                    3|2020-02-03|    0|\n",
      "|            Kerala|                    3|2020-02-04|    0|\n",
      "|            Kerala|                    3|2020-02-05|    0|\n",
      "|            Kerala|                    3|2020-02-06|    0|\n",
      "|            Kerala|                    3|2020-02-07|    0|\n",
      "|            Kerala|                    3|2020-02-08|    0|\n",
      "|            Kerala|                    3|2020-02-09|    0|\n",
      "|            Kerala|                    3|2020-02-10|    0|\n",
      "|            Kerala|                    3|2020-02-11|    0|\n",
      "|            Kerala|                    3|2020-02-12|    0|\n",
      "|            Kerala|                    3|2020-02-13|    0|\n",
      "|            Kerala|                    3|2020-02-14|    0|\n",
      "|            Kerala|                    3|2020-02-15|    0|\n",
      "|            Kerala|                    3|2020-02-16|    0|\n",
      "|            Kerala|                    3|2020-02-17|    0|\n",
      "|            Kerala|                    3|2020-02-18|    0|\n",
      "|            Kerala|                    3|2020-02-19|    0|\n",
      "|            Kerala|                    3|2020-02-20|    0|\n",
      "|            Kerala|                    3|2020-02-21|    0|\n",
      "|            Kerala|                    3|2020-02-22|    0|\n",
      "|            Kerala|                    3|2020-02-23|    0|\n",
      "|            Kerala|                    3|2020-02-24|    0|\n",
      "|            Kerala|                    3|2020-02-25|    0|\n",
      "|            Kerala|                    3|2020-02-26|    0|\n",
      "|            Kerala|                    3|2020-02-27|    0|\n",
      "|            Kerala|                    3|2020-02-28|    0|\n",
      "|            Kerala|                    3|2020-02-29|    0|\n",
      "|            Kerala|                    3|2020-03-01|    0|\n",
      "|            Kerala|                    3|2020-03-02|    0|\n",
      "|            Kerala|                    3|2020-03-03|    0|\n",
      "|            Kerala|                    3|2020-03-04|    0|\n",
      "|            Kerala|                    3|2020-03-05|    0|\n",
      "|            Kerala|                    3|2020-03-06|    0|\n",
      "|            Kerala|                    3|2020-03-07|    0|\n",
      "|            Kerala|                    8|2020-03-08|    0|\n",
      "|            Kerala|                    9|2020-03-09|    0|\n",
      "|            Kerala|                   15|2020-03-10|    0|\n",
      "|            Kerala|                   17|2020-03-11|    0|\n",
      "|            Kerala|                   17|2020-03-12|    0|\n",
      "|            Kerala|                   17|2020-03-13|    0|\n",
      "|            Kerala|                   19|2020-03-14|    0|\n",
      "|            Kerala|                   23|2020-03-15|    0|\n",
      "|            Kerala|                   23|2020-03-16|    0|\n",
      "|            Kerala|                   26|2020-03-17|    0|\n",
      "|            Kerala|                   27|2020-03-18|    0|\n",
      "|            Kerala|                   27|2020-03-19|    0|\n",
      "+------------------+---------------------+----------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "cd2k = cd2.select('Name of State / UT','Total Confirmed cases','Date','Death').filter(col('Name of State / UT') == \"Kerala\")\n",
    "cd2k.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|Total Confirmed cases|Death|\n",
      "+---------------------+-----+\n",
      "|                    1|    0|\n",
      "|                    1|    0|\n",
      "|                    2|    0|\n",
      "+---------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data= cd2k.select('Total Confirmed cases','Death')\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Integer features to vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['Total Confirmed cases'], outputCol = 'features')\n",
    "data = vectorAssembler.transform(data)\n",
    "data = data.select(['features', 'Death'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, Death: int]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0030966812496913123]\n",
      "Intercept: 2.9961498569203764\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='Death', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.668371\n",
      "r2: 0.972918\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             Death|\n",
      "+-------+------------------+\n",
      "|  count|               128|\n",
      "|   mean|         15.109375|\n",
      "| stddev|22.378714005750666|\n",
      "|    min|                 0|\n",
      "|    max|                94|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------+\n",
      "|        prediction|Death|features|\n",
      "+------------------+-----+--------+\n",
      "|2.9992465381700675|    0|   [1.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "+------------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.907918\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"Death\",\"features\").show(5)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"Death\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.87808\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding residual for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numIterations: 2\n",
      "objectiveHistory: [0.4999999999999999, 0.4040780248977257, 0.02529205901871722]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(residuals=1.3857626632171645),\n",
       " Row(residuals=-1.23425771767198),\n",
       " Row(residuals=-2.213265079875015),\n",
       " Row(residuals=-2.566970873290714),\n",
       " Row(residuals=0.7324950333281777)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numIterations: 2\n",
      "objectiveHistory: [0.4999999999999999, 0.4040780248977257, 0.02529205901871722]\n",
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "|-2.9992465381700675|\n",
      "| -3.002343219419759|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "|  -3.00543990066945|\n",
      "| -3.020923306917907|\n",
      "| -3.042600075665746|\n",
      "|-3.0487934381651285|\n",
      "|-3.0673735256632764|\n",
      "| -3.082856931911733|\n",
      "| -3.120017106908029|\n",
      "|-3.1571772819043247|\n",
      "| -3.290334575641051|\n",
      "|-3.3615582443839513|\n",
      "| -3.420395188128086|\n",
      "|-3.5411657568660475|\n",
      "|-2.5597458443641954|\n",
      "|-2.5969060193604907|\n",
      "+-------------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------+\n",
      "|        prediction|Death|features|\n",
      "+------------------+-----+--------+\n",
      "|2.9992465381700675|    0|   [1.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "|  3.00543990066945|    0|   [3.0]|\n",
      "| 3.024019988167598|    0|   [9.0]|\n",
      "|3.0487934381651285|    0|  [17.0]|\n",
      "|3.0487934381651285|    0|  [17.0]|\n",
      "| 3.054986800664511|    0|  [19.0]|\n",
      "|3.0673735256632764|    0|  [23.0]|\n",
      "|3.0766635694123505|    0|  [26.0]|\n",
      "|3.0797602506620416|    0|  [27.0]|\n",
      "|3.0797602506620416|    0|  [27.0]|\n",
      "| 3.203627500649694|    0|  [67.0]|\n",
      "+------------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"Death\",\"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.931161\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'Death')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"Death\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(1, {0: 1.0})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+\n",
      "|prediction|Death|features|\n",
      "+----------+-----+--------+\n",
      "|       0.0|    0|   [1.0]|\n",
      "|       0.0|    0|   [3.0]|\n",
      "|       0.0|    0|   [3.0]|\n",
      "|       0.0|    0|   [3.0]|\n",
      "|       0.0|    0|   [3.0]|\n",
      "+----------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'Death', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'Death', 'features').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.914325\n"
     ]
    }
   ],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"Death\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>CovidIndia</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd82eb71750>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
